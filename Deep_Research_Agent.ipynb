{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Baishaki-sfdc/Deep_Research_Agent/blob/main/Deep_Research_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4169bfb-769a-4db3-833e-c827f19024b2",
      "metadata": {
        "id": "f4169bfb-769a-4db3-833e-c827f19024b2"
      },
      "source": [
        "# Planning Agent for Deep Research & Structured Report Generation with LangGraph\n",
        "\n",
        "\n",
        "This project focuses on  building a Planning Agent for Deep Research and Structured Report Generation in the form of Wiki-style Reports (structured with key sections and section headings)\n",
        "\n",
        "\n",
        "\n",
        "### Planning Agent for Deep Research and Structured Report Generation\n",
        "\n",
        "This project focuses on building a **Planning Agent for Deep Research and Structured Report Generation**. The agent automates the process of analyzing a user-defined topic, performing web research, and generating a well-structured report. The workflow includes the following components:\n",
        "\n",
        "1. **Report Planning**:\n",
        "   - The agent analyzes the user-provided **topic** and **default report template** to create a custom plan for the report.\n",
        "   - Sections such as **Introduction**, **Key Sections**, and **Conclusion** are defined based on the topic.\n",
        "   - A **web search tool** is used to collect information required before deciding the main sections.\n",
        "\n",
        "2. **Parallel Execution for Research and Writing**:\n",
        "   - The agent uses **parallel execution** to efficiently perform:\n",
        "     - **Web Research**: Queries are generated for each section and executed via the web search tool to retrieve up-to-date information.\n",
        "     - **Section Writing**: The retrieved data is used to write content for each section, with the following process:\n",
        "       - The **Researcher** gathers relevant data from the web.\n",
        "       - The **Section Writer** uses the data to generate structured content for the assigned section.\n",
        "\n",
        "3. **Formatting Completed Sections**:\n",
        "   - Once all sections are written, they are formatted to ensure consistency and adherence to the report structure.\n",
        "\n",
        "4. **Introduction and Conclusion Writing**:\n",
        "   - After the main sections are completed and formatted:\n",
        "     - The **Introduction** and **Conclusion** are written based on the content of the remaining sections (in parallel)\n",
        "     - This process ensures that these sections align with the overall flow and insights of the report.\n",
        "\n",
        "5. **Final Compilation**:\n",
        "   - All completed sections are compiled together to generate the **final report**.\n",
        "   - The final output is a comprehensive and structured document in the style of wiki docs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install OpenAI, LangGraph and LangChain dependencies"
      ],
      "metadata": {
        "id": "9hEI3WL328vZ"
      },
      "id": "9hEI3WL328vZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "618eab5c-4ef7-4273-8e0b-a9c847897ed7",
      "metadata": {
        "id": "618eab5c-4ef7-4273-8e0b-a9c847897ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "623834e2-4c4b-4b79-f18d-82f1cdf66c6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.14\n",
            "  Downloading langchain-0.3.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (0.3.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (0.3.8)\n",
            "Collecting langsmith<0.3,>=0.1.17 (from langchain==0.3.14)\n",
            "  Downloading langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1.22.4 (from langchain==0.3.14)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m823.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (2.11.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.14) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.19.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.14) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14) (3.2.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain-openai==0.3.0\n",
            "  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.0) (0.3.52)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.58.1 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.3.0) (1.75.0)\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langchain-community==0.3.14\n",
            "  Downloading langchain_community-0.3.14-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (3.11.15)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.14)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community==0.3.14)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (0.3.23)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (0.3.52)\n",
            "Collecting langsmith<0.3,>=0.1.125 (from langchain-community==0.3.14)\n",
            "  Using cached langsmith-0.2.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting numpy<2,>=1.22.4 (from langchain-community==0.3.14)\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.14)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.14) (9.1.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.14) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.14)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.14) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.3.14) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.14) (3.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community==0.3.14) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community==0.3.14) (2.33.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.14)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community==0.3.14) (1.3.1)\n",
            "Downloading langchain_community-0.3.14-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langsmith-0.2.11-py3-none-any.whl (326 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, numpy, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langsmith, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.31\n",
            "    Uninstalling langsmith-0.3.31:\n",
            "      Successfully uninstalled langsmith-0.3.31\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting langgraph==0.2.64\n",
            "  Downloading langgraph-0.2.64-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in /usr/local/lib/python3.11/dist-packages (from langgraph==0.2.64) (0.3.52)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph==0.2.64)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph==0.2.64)\n",
            "  Downloading langgraph_sdk-0.1.63-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.2.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (4.13.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.11.3)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph==0.2.64)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (3.10.16)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (1.0.8)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph==0.2.64) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph==0.2.64) (1.3.1)\n",
            "Downloading langgraph-0.2.64-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.6/142.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_sdk-0.1.63-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph\n",
            "Successfully installed langgraph-0.2.64 langgraph-checkpoint-2.0.24 langgraph-sdk-0.1.63 ormsgpack-1.9.1\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.3.14\n",
        "!pip install langchain-openai==0.3.0\n",
        "!pip install langchain-community==0.3.14\n",
        "!pip install langgraph==0.2.64\n",
        "!pip install rich"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Open AI API Key"
      ],
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "id": "H9c37cLnSrbg"
    },
    {
      "cell_type": "code",
      "source": [
        "OPENAI_API_KEY = getpass('Enter OpenAI API Key: ')"
      ],
      "metadata": {
        "id": "cv3JzCEx_PAd"
      },
      "execution_count": null,
      "outputs": [],
      "id": "cv3JzCEx_PAd"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ],
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "id": "ucWRRI3QztL2"
    },
    {
      "cell_type": "code",
      "source": [
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ],
      "metadata": {
        "id": "mK-1WLzOrJdb"
      },
      "execution_count": null,
      "outputs": [],
      "id": "mK-1WLzOrJdb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup Environment Variables"
      ],
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "id": "1T0s0um5Svfa"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ],
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "execution_count": null,
      "outputs": [],
      "id": "x1YSuHNF_lbh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Agent State Schema\n",
        "\n",
        "Each specific set of operations (nodes) will have their own schema as defined below. You can customize this further based on your own style of report generation"
      ],
      "metadata": {
        "id": "1Anj_VT7b4Rt"
      },
      "id": "1Anj_VT7b4Rt"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "import operator\n",
        "from typing import  Annotated, List, Optional, Literal\n",
        "\n",
        "class Section(BaseModel):\n",
        "    name: str = Field(\n",
        "        description=\"Name for a particular section of the report.\",\n",
        "    )\n",
        "    description: str = Field(\n",
        "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
        "    )\n",
        "    research: bool = Field(\n",
        "        description=\"Whether to perform web search for this section of the report.\"\n",
        "    )\n",
        "    content: str = Field(\n",
        "        description=\"The content for this section.\"\n",
        "    )\n",
        "\n",
        "class Sections(BaseModel):\n",
        "    sections: List[Section] = Field(\n",
        "        description=\"All the Sections of the overall report.\",\n",
        "    )\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    search_query: str = Field(None, description=\"Query for web search.\")\n",
        "\n",
        "class Queries(BaseModel):\n",
        "    queries: List[SearchQuery] = Field(\n",
        "        description=\"List of web search queries.\",\n",
        "    )\n",
        "\n",
        "class ReportStateInput(TypedDict):\n",
        "    topic: str # Report topic\n",
        "\n",
        "class ReportStateOutput(TypedDict):\n",
        "    final_report: str # Final report\n",
        "\n",
        "class ReportState(TypedDict):\n",
        "    topic: str # Report topic\n",
        "    sections: list[Section] # List of report sections\n",
        "    completed_sections: Annotated[list, operator.add] # Send() API\n",
        "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
        "    final_report: str # Final report\n",
        "\n",
        "class SectionState(TypedDict):\n",
        "    section: Section # Report section\n",
        "    search_queries: list[SearchQuery] # List of search queries\n",
        "    source_str: str # String of formatted source content from web search\n",
        "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
        "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
        "\n",
        "class SectionOutputState(TypedDict):\n",
        "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n"
      ],
      "metadata": {
        "id": "o7EnucYkRb6f"
      },
      "id": "o7EnucYkRb6f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions\n",
        "\n",
        "- __`run_search_queries(...)`__ : This will asynchronously run tavily search queries for specific list of queries and return back the search results. This is async so it is non blocking and can be executed in parallel."
      ],
      "metadata": {
        "id": "J8gh0PeLnoD8"
      },
      "id": "J8gh0PeLnoD8"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "import asyncio\n",
        "from dataclasses import asdict, dataclass\n",
        "\n",
        "\n",
        "# just to handle objects created from LLM reponses\n",
        "@dataclass\n",
        "class SearchQuery:\n",
        "    search_query: str\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        return asdict(self)\n",
        "\n",
        "\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "\n",
        "async def run_search_queries(\n",
        "    search_queries: List[Union[str, SearchQuery]],\n",
        "    num_results: int = 5,\n",
        "    include_raw_content: bool = False\n",
        ") -> List[Dict]:\n",
        "\n",
        "    search_tasks = []\n",
        "\n",
        "    for query in search_queries:\n",
        "        # Handle both string and SearchQuery objects\n",
        "        # Just in case LLM fails to generate queries as:\n",
        "        # class SearchQuery(BaseModel):\n",
        "        #     search_query: str\n",
        "        query_str = query.search_query if isinstance(query, SearchQuery) else str(query) # text query\n",
        "\n",
        "        try:\n",
        "            # get results from tavily asynchronously (in parallel) for each search query\n",
        "            search_tasks.append(\n",
        "                tavily_search.raw_results_async(\n",
        "                    query=query_str,\n",
        "                    max_results=num_results,\n",
        "                    search_depth='advanced',\n",
        "                    include_answer=False,\n",
        "                    include_raw_content=include_raw_content\n",
        "                )\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating search task for query '{query_str}': {e}\")\n",
        "            continue\n",
        "\n",
        "    # Execute all searches concurrently and await results\n",
        "    try:\n",
        "        if not search_tasks:\n",
        "            return []\n",
        "        search_docs = await asyncio.gather(*search_tasks, return_exceptions=True)\n",
        "        # Filter out any exceptions from the results\n",
        "        valid_results = [\n",
        "            doc for doc in search_docs\n",
        "            if not isinstance(doc, Exception)\n",
        "        ]\n",
        "        return valid_results\n",
        "    except Exception as e:\n",
        "        print(f\"Error during search queries: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "x90h-0URszgf"
      },
      "id": "x90h-0URszgf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- __`format_search_query_results(...)`__ : This will extract the context from tavily search results, make sure content is not duplicated from same urls and format it to show the Source, URL, relevant content (and optionally raw content which can be truncated based on number of tokens)"
      ],
      "metadata": {
        "id": "Db-RKn5MCi47"
      },
      "id": "Db-RKn5MCi47"
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "from typing import List, Dict, Union, Any\n",
        "\n",
        "def format_search_query_results(\n",
        "    search_response: Union[Dict[str, Any], List[Any]],\n",
        "    max_tokens: int = 2000,\n",
        "    include_raw_content: bool = False\n",
        ") -> str:\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    sources_list = []\n",
        "\n",
        "    # Handle different response formats\n",
        "    # if search results is a dict\n",
        "    if isinstance(search_response, dict):\n",
        "        if 'results' in search_response:\n",
        "            sources_list.extend(search_response['results'])\n",
        "        else:\n",
        "            sources_list.append(search_response)\n",
        "    # if search results is a list\n",
        "    elif isinstance(search_response, list):\n",
        "        for response in search_response:\n",
        "            if isinstance(response, dict):\n",
        "                if 'results' in response:\n",
        "                    sources_list.extend(response['results'])\n",
        "                else:\n",
        "                    sources_list.append(response)\n",
        "            elif isinstance(response, list):\n",
        "                sources_list.extend(response)\n",
        "\n",
        "    if not sources_list:\n",
        "        return \"No search results found.\"\n",
        "\n",
        "    # Deduplicate by URL and keep unique sources (website urls)\n",
        "    unique_sources = {}\n",
        "    for source in sources_list:\n",
        "        if isinstance(source, dict) and 'url' in source:\n",
        "            if source['url'] not in unique_sources:\n",
        "                unique_sources[source['url']] = source\n",
        "\n",
        "    # Format output\n",
        "    formatted_text = \"Content from web search:\\n\\n\"\n",
        "    for i, source in enumerate(unique_sources.values(), 1):\n",
        "        formatted_text += f\"Source {source.get('title', 'Untitled')}:\\n===\\n\"\n",
        "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
        "        formatted_text += f\"Most relevant content from source: {source.get('content', 'No content available')}\\n===\\n\"\n",
        "\n",
        "        if include_raw_content:\n",
        "            # truncate raw webpage content to a certain number of tokens to prevent exceeding LLM max token window\n",
        "            raw_content = source.get(\"raw_content\", \"\")\n",
        "            if raw_content:\n",
        "                tokens = encoding.encode(raw_content)\n",
        "                truncated_tokens = tokens[:max_tokens]\n",
        "                truncated_content = encoding.decode(truncated_tokens)\n",
        "                formatted_text += f\"Raw Content: {truncated_content}\\n\\n\"\n",
        "\n",
        "    return formatted_text.strip()"
      ],
      "metadata": {
        "id": "E9YSh5pAxW5r"
      },
      "id": "E9YSh5pAxW5r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Sample Utility Functions"
      ],
      "metadata": {
        "id": "lM0iTr7iC-17"
      },
      "id": "lM0iTr7iC-17"
    },
    {
      "cell_type": "code",
      "source": [
        "docs = await run_search_queries(['langgraph'], include_raw_content=True)\n",
        "docs"
      ],
      "metadata": {
        "id": "60GtL630zXH4"
      },
      "id": "60GtL630zXH4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "zFNI1k9bKmBP"
      },
      "id": "zFNI1k9bKmBP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = format_search_query_results(docs, max_tokens=500, include_raw_content=True)"
      ],
      "metadata": {
        "id": "naEyCquUxiFT"
      },
      "id": "naEyCquUxiFT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output)"
      ],
      "metadata": {
        "id": "qHJ7CU1ixoLI"
      },
      "id": "qHJ7CU1ixoLI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Default Report Template\n",
        "\n",
        "This is the starting point for the LLM to get an idea of how to build a general report and it will use this to build a custom report structure"
      ],
      "metadata": {
        "id": "TVjGRN57M1Zp"
      },
      "id": "TVjGRN57M1Zp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Structure\n",
        "DEFAULT_REPORT_STRUCTURE = \"\"\"The report structure should focus on breaking-down the user-provided topic\n",
        "                              and building a comprehensive report in markdown using the following format:\n",
        "\n",
        "                              1. Introduction (no web search needed)\n",
        "                                    - Brief overview of the topic area\n",
        "\n",
        "                              2. Main Body Sections:\n",
        "                                    - Each section should focus on a sub-topic of the user-provided topic\n",
        "                                    - Include any key concepts and definitions\n",
        "                                    - Provide real-world examples or case studies where applicable\n",
        "\n",
        "                              3. Conclusion (no web search needed)\n",
        "                                    - Aim for 1 structural element (either a list of table) that distills the main body sections\n",
        "                                    - Provide a concise summary of the report\n",
        "\n",
        "                              When generating the final response in markdown, if there are special characters in the text,\n",
        "                              such as the dollar symbol, ensure they are escaped properly for correct rendering e.g $25.5 should become \\$25.5\n",
        "                          \"\"\""
      ],
      "metadata": {
        "id": "_Mub1ld70yih"
      },
      "id": "_Mub1ld70yih",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instruction Prompts for Report Planner\n",
        "\n",
        "There are two main instruction prompts:\n",
        "\n",
        "- __REPORT_PLAN_QUERY_GENERATOR_PROMPT:__ Helps the LLM to generate an initial list of questions based on the topic to get more information from the web about that topic so that it can plan the overall sections and structure of the report\n",
        "\n",
        "- __REPORT_PLAN_SECTION_GENERATOR_PROMPT:__ Here we feed the LLM with the default report template, the topic name and the search results from the intial queries generated to create a detailed structure for the report. The LLM will generate a structured response of the following fields for each major section which will be in the report (this is just the report structure - no content is created at this step):\n",
        "    - Name - Name for this section of the report.\n",
        "    - Description - Brief overview of the main topics and concepts to be covered in this section.\n",
        "    - Research - Whether to perform web search for this section of the report or not.\n",
        "    - Content - The content of the section, which you will leave blank for now."
      ],
      "metadata": {
        "id": "w-R-V_1SM-Rn"
      },
      "id": "w-R-V_1SM-Rn"
    },
    {
      "cell_type": "code",
      "source": [
        "REPORT_PLAN_QUERY_GENERATOR_PROMPT = \"\"\"You are an expert technical report writer, helping to plan a report.\n",
        "\n",
        "The report will be focused on the following topic:\n",
        "{topic}\n",
        "\n",
        "The report structure will follow these guidelines:\n",
        "{report_organization}\n",
        "\n",
        "Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information for planning the report sections.\n",
        "\n",
        "The query should:\n",
        "1. Be related to the topic\n",
        "2. Help satisfy the requirements specified in the report organization\n",
        "\n",
        "Make the query specific enough to find high-quality, relevant sources while covering the depth and breadth needed for the report structure.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "vjoRG-IP0zkx"
      },
      "id": "vjoRG-IP0zkx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REPORT_PLAN_SECTION_GENERATOR_PROMPT = \"\"\"You are an expert technical report writer, helping to plan a report.\n",
        "\n",
        "Your goal is to generate the outline of the sections of the report.\n",
        "\n",
        "The overall topic of the report is:\n",
        "{topic}\n",
        "\n",
        "The report should follow this organizational structure:\n",
        "{report_organization}\n",
        "\n",
        "You should reflect on this additional context information from web searches to plan the main sections of the report:\n",
        "{search_context}\n",
        "\n",
        "Now, generate the sections of the report. Each section should have the following fields:\n",
        "- Name - Name for this section of the report.\n",
        "- Description - Brief overview of the main topics and concepts to be covered in this section.\n",
        "- Research - Whether to perform web search for this section of the report or not.\n",
        "- Content - The content of the section, which you will leave blank for now.\n",
        "\n",
        "Consider which sections require web search.\n",
        "For example, introduction and conclusion will not require research because they will distill information from other parts of the report.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "qBjAzBjd2pYa"
      },
      "id": "qBjAzBjd2pYa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Function for Report Planner\n",
        "\n",
        "\n",
        "\n",
        "This function uses the two prompts created above to:\n",
        " - First generate some queries based on the user topic\n",
        " - Search the web and get some information on these queries\n",
        " - Use this information to generate the overall structure of the report with the key sections necessary to be created"
      ],
      "metadata": {
        "id": "BcGmRLcQOE-U"
      },
      "id": "BcGmRLcQOE-U"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "async def generate_report_plan(state: ReportState):\n",
        "    \"\"\"Generate the overall plan for building the report\"\"\"\n",
        "    topic = state[\"topic\"]\n",
        "    print('--- Generating Report Plan ---')\n",
        "\n",
        "    report_structure = DEFAULT_REPORT_STRUCTURE\n",
        "    number_of_queries = 8\n",
        "\n",
        "    structured_llm = llm.with_structured_output(Queries)\n",
        "\n",
        "    system_instructions_query = REPORT_PLAN_QUERY_GENERATOR_PROMPT.format(\n",
        "        topic=topic,\n",
        "        report_organization=report_structure,\n",
        "        number_of_queries=number_of_queries\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Generate queries\n",
        "        results = structured_llm.invoke([\n",
        "            SystemMessage(content=system_instructions_query),\n",
        "            HumanMessage(content='Generate search queries that will help with planning the sections of the report.')\n",
        "        ])\n",
        "\n",
        "        # Convert SearchQuery objects to strings\n",
        "        query_list = [\n",
        "            query.search_query if isinstance(query, SearchQuery) else str(query)\n",
        "            for query in results.queries\n",
        "        ]\n",
        "\n",
        "        # Search web and ensure we wait for results\n",
        "        search_docs = await run_search_queries(\n",
        "            query_list,\n",
        "            num_results=5,\n",
        "            include_raw_content=False\n",
        "        )\n",
        "\n",
        "        if not search_docs:\n",
        "            print(\"Warning: No search results returned\")\n",
        "            search_context = \"No search results available.\"\n",
        "        else:\n",
        "            search_context = format_search_query_results(\n",
        "                search_docs,\n",
        "                include_raw_content=False\n",
        "            )\n",
        "\n",
        "        # Generate sections\n",
        "        system_instructions_sections = REPORT_PLAN_SECTION_GENERATOR_PROMPT.format(\n",
        "            topic=topic,\n",
        "            report_organization=report_structure,\n",
        "            search_context=search_context\n",
        "        )\n",
        "\n",
        "        structured_llm = llm.with_structured_output(Sections)\n",
        "        report_sections = structured_llm.invoke([\n",
        "            SystemMessage(content=system_instructions_sections),\n",
        "            HumanMessage(content=\"Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. Each section must have: name, description, plan, research, and content fields.\")\n",
        "        ])\n",
        "\n",
        "        print('--- Generating Report Plan Completed ---')\n",
        "        return {\"sections\": report_sections.sections}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generate_report_plan: {e}\")\n",
        "        return {\"sections\": []}"
      ],
      "metadata": {
        "id": "OH8ihSnZ0hHf"
      },
      "id": "OH8ihSnZ0hHf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instruction Prompts for Section Builder - Query Generator\n",
        "\n",
        "There is one main instruction prompt:\n",
        "\n",
        "- __REPORT_SECTION_QUERY_GENERATOR_PROMPT:__ Helps the LLM to generate a comprehensive list of questions for the topic of that specific section which needs to be built"
      ],
      "metadata": {
        "id": "j8zCsQwuQbeO"
      },
      "id": "j8zCsQwuQbeO"
    },
    {
      "cell_type": "code",
      "source": [
        "REPORT_SECTION_QUERY_GENERATOR_PROMPT = \"\"\"Your goal is to generate targeted web search queries that will gather comprehensive information for writing a technical report section.\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "When generating {number_of_queries} search queries, ensure that they:\n",
        "1. Cover different aspects of the topic (e.g., core features, real-world applications, technical architecture)\n",
        "2. Include specific technical terms related to the topic\n",
        "3. Target recent information by including year markers where relevant (e.g., \"2024\")\n",
        "4. Look for comparisons or differentiators from similar technologies/approaches\n",
        "5. Search for both official documentation and practical implementation examples\n",
        "\n",
        "Your queries should be:\n",
        "- Specific enough to avoid generic results\n",
        "- Technical enough to capture detailed implementation information\n",
        "- Diverse enough to cover all aspects of the section plan\n",
        "- Focused on authoritative sources (documentation, technical blogs, academic papers)\"\"\""
      ],
      "metadata": {
        "id": "uxLrzsyY5Mdl"
      },
      "id": "uxLrzsyY5Mdl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Function for Section Builder - Generate Queries (Query Generator)\n",
        "\n",
        "This uses the section topic and the instruction prompt above to generate some questions for researching on the web for getting useful information on the section topic"
      ],
      "metadata": {
        "id": "JP6AVB1YRqpG"
      },
      "id": "JP6AVB1YRqpG"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_queries(state: SectionState):\n",
        "    \"\"\" Generate search queries for a specific report section \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    print('--- Generating Search Queries for Section: '+ section.name +' ---')\n",
        "\n",
        "    # Get configuration\n",
        "    number_of_queries = 5\n",
        "\n",
        "    # Generate queries\n",
        "    structured_llm = llm.with_structured_output(Queries)\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = REPORT_SECTION_QUERY_GENERATOR_PROMPT.format(section_topic=section.description,\n",
        "                                                                       number_of_queries=number_of_queries)\n",
        "\n",
        "    # Generate queries\n",
        "    user_instruction = \"Generate search queries on the provided topic.\"\n",
        "    search_queries = structured_llm.invoke([SystemMessage(content=system_instructions),\n",
        "                                     HumanMessage(content=user_instruction)])\n",
        "\n",
        "    print('--- Generating Search Queries for Section: '+ section.name +' Completed ---')\n",
        "\n",
        "    return {\"search_queries\": search_queries.queries}"
      ],
      "metadata": {
        "id": "1tdPfB6m3taO"
      },
      "id": "1tdPfB6m3taO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Function for Section Builder - Search Web\n",
        "\n",
        "Takes the queries generated by `generate_queries(...)`for a specific section, searches the web and formats the search results using the utility functions we defined earlier"
      ],
      "metadata": {
        "id": "6G_8doZxR8QC"
      },
      "id": "6G_8doZxR8QC"
    },
    {
      "cell_type": "code",
      "source": [
        "async def search_web(state: SectionState):\n",
        "    \"\"\" Search the web for each query, then return a list of raw sources and a formatted string of sources.\"\"\"\n",
        "\n",
        "    # Get state\n",
        "    search_queries = state[\"search_queries\"]\n",
        "\n",
        "    print('--- Searching Web for Queries ---')\n",
        "\n",
        "    # Web search\n",
        "    query_list = [query.search_query for query in search_queries]\n",
        "    search_docs = await run_search_queries(search_queries, num_results=6, include_raw_content=True)\n",
        "\n",
        "    # Deduplicate and format sources\n",
        "    search_context = format_search_query_results(search_docs, max_tokens=4000, include_raw_content=True)\n",
        "\n",
        "    print('--- Searching Web for Queries Completed ---')\n",
        "\n",
        "    return {\"source_str\": search_context}\n"
      ],
      "metadata": {
        "id": "Te1lHnkqRcBH"
      },
      "id": "Te1lHnkqRcBH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instruction Prompts for Section Builder - Section Writer\n",
        "\n",
        "There is one main instruction prompt:\n",
        "\n",
        "- __SECTION_WRITER_PROMPT:__ Constrains the LLM to generate and write the content for a specific section using certain guidelines on style, structure, length, approach and the documents obtained from the web earlier using the `search_web(...)` function are also sent."
      ],
      "metadata": {
        "id": "5_ytIcDFUQMZ"
      },
      "id": "5_ytIcDFUQMZ"
    },
    {
      "cell_type": "code",
      "source": [
        "SECTION_WRITER_PROMPT = \"\"\"You are an expert technical writer crafting one specific section of a technical report.\n",
        "\n",
        "Title for the section:\n",
        "{section_title}\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "Guidelines for writing:\n",
        "\n",
        "1. Technical Accuracy:\n",
        "- Include specific version numbers\n",
        "- Reference concrete metrics/benchmarks\n",
        "- Cite official documentation\n",
        "- Use technical terminology precisely\n",
        "\n",
        "2. Length and Style:\n",
        "- Strict 150-200 word limit\n",
        "- No marketing language\n",
        "- Technical focus\n",
        "- Write in simple, clear language do not use complex words unnecessarily\n",
        "- Start with your most important insight in **bold**\n",
        "- Use short paragraphs (2-3 sentences max)\n",
        "\n",
        "3. Structure:\n",
        "- Use ## for section title (Markdown format)\n",
        "- Only use ONE structural element IF it helps clarify your point:\n",
        "  * Either a focused table comparing 2-3 key items (using Markdown table syntax)\n",
        "  * Or a short list (3-5 items) using proper Markdown list syntax:\n",
        "    - Use `*` or `-` for unordered lists\n",
        "    - Use `1.` for ordered lists\n",
        "    - Ensure proper indentation and spacing\n",
        "- End with ### Sources that references the below source material formatted as:\n",
        "  * List each source with title, date, and URL\n",
        "  * Format: `- Title : URL`\n",
        "\n",
        "3. Writing Approach:\n",
        "- Include at least one specific example or case study if available\n",
        "- Use concrete details over general statements\n",
        "- Make every word count\n",
        "- No preamble prior to creating the section content\n",
        "- Focus on your single most important point\n",
        "\n",
        "4. Use this source material obtained from web searches to help write the section:\n",
        "{context}\n",
        "\n",
        "5. Quality Checks:\n",
        "- Format should be Markdown\n",
        "- Exactly 150-200 words (excluding title and sources)\n",
        "- Careful use of only ONE structural element (table or bullet list) and only if it helps clarify your point\n",
        "- One specific example / case study if available\n",
        "- Starts with bold insight\n",
        "- No preamble prior to creating the section content\n",
        "- Sources cited at end\n",
        "- If there are special characters in the text, such as the dollar symbol,\n",
        "  ensure they are escaped properly for correct rendering e.g $25.5 should become \\$25.5\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Fc8VGgaK-UkT"
      },
      "id": "Fc8VGgaK-UkT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node Function for Section Builder - Write Section (Section Writer)\n",
        "\n",
        "Uses the SECTION_WRITER_PROMPT from above and feeds it with the section name, description and web search documents and passes it to an LLM to write the content for that section"
      ],
      "metadata": {
        "id": "5Vg97bh3USLp"
      },
      "id": "5Vg97bh3USLp"
    },
    {
      "cell_type": "code",
      "source": [
        "def write_section(state: SectionState):\n",
        "    \"\"\" Write a section of the report \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    source_str = state[\"source_str\"]\n",
        "\n",
        "    print('--- Writing Section : '+ section.name +' ---')\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = SECTION_WRITER_PROMPT.format(section_title=section.name,\n",
        "                                                       section_topic=section.description,\n",
        "                                                       context=source_str)\n",
        "\n",
        "    # Generate section\n",
        "    user_instruction = \"Generate a report section based on the provided sources.\"\n",
        "    section_content = llm.invoke([SystemMessage(content=system_instructions),\n",
        "                                  HumanMessage(content=user_instruction)])\n",
        "\n",
        "    # Write content to the section object\n",
        "    section.content = section_content.content\n",
        "\n",
        "    print('--- Writing Section : '+ section.name +' Completed ---')\n",
        "\n",
        "    # Write the updated section to completed sections\n",
        "    return {\"completed_sections\": [section]}"
      ],
      "metadata": {
        "id": "mSgrxeeJ8I-O"
      },
      "id": "mSgrxeeJ8I-O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Section Builder Sub-Agent\n",
        "\n",
        "\n",
        "\n",
        "This agent (or to be more specific, sub-agent) will be called several times in parallel, once for each section to search the web, get content and then write up that specific section"
      ],
      "metadata": {
        "id": "JIvVGOPwSNgQ"
      },
      "id": "JIvVGOPwSNgQ"
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Add nodes and edges\n",
        "section_builder = StateGraph(SectionState, output=SectionOutputState)\n",
        "section_builder.add_node(\"generate_queries\", generate_queries)\n",
        "section_builder.add_node(\"search_web\", search_web)\n",
        "section_builder.add_node(\"write_section\", write_section)\n",
        "\n",
        "section_builder.add_edge(START, \"generate_queries\")\n",
        "section_builder.add_edge(\"generate_queries\", \"search_web\")\n",
        "section_builder.add_edge(\"search_web\", \"write_section\")\n",
        "section_builder.add_edge(\"write_section\", END)\n",
        "section_builder_subagent = section_builder.compile()"
      ],
      "metadata": {
        "id": "UYB9crmZRcDD"
      },
      "id": "UYB9crmZRcDD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the graph\n",
        "from IPython.display import display, Image\n",
        "Image(section_builder_subagent.get_graph().draw_mermaid_png())"
      ],
      "metadata": {
        "id": "kkGDMBRTRcFx"
      },
      "id": "kkGDMBRTRcFx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dynamic Parallelization Node Function - Parallelize Section Writing\n",
        "\n",
        "`Send(...)` is used to parallelize and call the `section_builder_subagent` once for each section to write up the content (in parallel)"
      ],
      "metadata": {
        "id": "jrw1YPEHWD12"
      },
      "id": "jrw1YPEHWD12"
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.constants import Send\n",
        "\n",
        "def parallelize_section_writing(state: ReportState):\n",
        "    \"\"\" This is the \"map\" step when we kick off web research for some sections of the report in parallel and then write the section\"\"\"\n",
        "\n",
        "    # Kick off section writing in parallel via Send() API for any sections that require research\n",
        "    return [\n",
        "        Send(\"section_builder_with_web_search\", # name of the subagent node\n",
        "             {\"section\": s})\n",
        "            for s in state[\"sections\"]\n",
        "              if s.research\n",
        "    ]"
      ],
      "metadata": {
        "id": "W7_5uWR2DkgN"
      },
      "id": "W7_5uWR2DkgN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Format Sections Node Function\n",
        "\n",
        "This is basically the section where all the sections are formatted and combined together into one big document.\n"
      ],
      "metadata": {
        "id": "YDquAhSNYz06"
      },
      "id": "YDquAhSNYz06"
    },
    {
      "cell_type": "code",
      "source": [
        "def format_sections(sections: list[Section]) -> str:\n",
        "    \"\"\" Format a list of report sections into a single text string \"\"\"\n",
        "    formatted_str = \"\"\n",
        "    for idx, section in enumerate(sections, 1):\n",
        "        formatted_str += f\"\"\"\n",
        "{'='*60}\n",
        "Section {idx}: {section.name}\n",
        "{'='*60}\n",
        "Description:\n",
        "{section.description}\n",
        "Requires Research:\n",
        "{section.research}\n",
        "\n",
        "Content:\n",
        "{section.content if section.content else '[Not yet written]'}\n",
        "\n",
        "\"\"\"\n",
        "    return formatted_str\n",
        "\n",
        "\n",
        "def format_completed_sections(state: ReportState):\n",
        "    \"\"\" Gather completed sections from research and format them as context for writing the final sections \"\"\"\n",
        "\n",
        "    print('--- Formatting Completed Sections ---')\n",
        "\n",
        "    # List of completed sections\n",
        "    completed_sections = state[\"completed_sections\"]\n",
        "\n",
        "    # Format completed section to str to use as context for final sections\n",
        "    completed_report_sections = format_sections(completed_sections)\n",
        "\n",
        "    print('--- Formatting Completed Sections is Done ---')\n",
        "\n",
        "    return {\"report_sections_from_research\": completed_report_sections}\n"
      ],
      "metadata": {
        "id": "uNlTvupUCHI9"
      },
      "id": "uNlTvupUCHI9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instruction Prompts for Final Section\n",
        "\n",
        "There is one main instruction prompt:\n",
        "\n",
        "- __FINAL_SECTION_WRITER_PROMPT:__ Constrains the LLM to generate and write the content for either the introduction OR conclusion using certain guidelines on style, structure, length, approach and the content of the already written sections are also sent."
      ],
      "metadata": {
        "id": "l22EjIp1ZUTj"
      },
      "id": "l22EjIp1ZUTj"
    },
    {
      "cell_type": "code",
      "source": [
        "FINAL_SECTION_WRITER_PROMPT = \"\"\"You are an expert technical writer crafting a section that synthesizes information from the rest of the report.\n",
        "\n",
        "Title for the section:\n",
        "{section_title}\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "Available report content of already completed sections:\n",
        "{context}\n",
        "\n",
        "1. Section-Specific Approach:\n",
        "\n",
        "For Introduction:\n",
        "- Use # for report title (Markdown format)\n",
        "- 50-100 word limit\n",
        "- Write in simple and clear language\n",
        "- Focus on the core motivation for the report in 1-2 paragraphs\n",
        "- Use a clear narrative arc to introduce the report\n",
        "- Include NO structural elements (no lists or tables)\n",
        "- No sources section needed\n",
        "\n",
        "For Conclusion/Summary:\n",
        "- Use ## for section title (Markdown format)\n",
        "- 100-150 word limit\n",
        "- For comparative reports:\n",
        "    * Must include a focused comparison table using Markdown table syntax\n",
        "    * Table should distill insights from the report\n",
        "    * Keep table entries clear and concise\n",
        "- For non-comparative reports:\n",
        "    * Only use ONE structural element IF it helps distill the points made in the report:\n",
        "    * Either a focused table comparing items present in the report (using Markdown table syntax)\n",
        "    * Or a short list using proper Markdown list syntax:\n",
        "      - Use `*` or `-` for unordered lists\n",
        "      - Use `1.` for ordered lists\n",
        "      - Ensure proper indentation and spacing\n",
        "- End with specific next steps or implications\n",
        "- No sources section needed\n",
        "\n",
        "3. Writing Approach:\n",
        "- Use concrete details over general statements\n",
        "- Make every word count\n",
        "- Focus on your single most important point\n",
        "\n",
        "4. Quality Checks:\n",
        "- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section\n",
        "- For conclusion: 100-150 word limit, ## for section title, only ONE structural element at most, no sources section\n",
        "- Markdown format\n",
        "- Do not include word count or any preamble in your response\n",
        "- If there are special characters in the text, such as the dollar symbol,\n",
        "  ensure they are escaped properly for correct rendering e.g $25.5 should become \\$25.5\"\"\""
      ],
      "metadata": {
        "id": "OEZqj7PFA2U_"
      },
      "id": "OEZqj7PFA2U_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Write Final Sections Node Function\n",
        "\n",
        "This function uses the instruction prompot FINAL_SECTION_WRITER_PROMPT mentioned above to write up the introduction and conclusion. This function will be executed in parallel using `Send(...)` below\n"
      ],
      "metadata": {
        "id": "Myztb9Eeb-88"
      },
      "id": "Myztb9Eeb-88"
    },
    {
      "cell_type": "code",
      "source": [
        "def write_final_sections(state: SectionState):\n",
        "    \"\"\" Write the final sections of the report, which do not require web search and use the completed sections as context\"\"\"\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    completed_report_sections = state[\"report_sections_from_research\"]\n",
        "\n",
        "    print('--- Writing Final Section: '+ section.name + ' ---')\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = FINAL_SECTION_WRITER_PROMPT.format(section_title=section.name,\n",
        "                                                             section_topic=section.description,\n",
        "                                                             context=completed_report_sections)\n",
        "\n",
        "    # Generate section\n",
        "    user_instruction = \"Craft a report section based on the provided sources.\"\n",
        "    section_content = llm.invoke([SystemMessage(content=system_instructions),\n",
        "                                  HumanMessage(content=user_instruction)])\n",
        "\n",
        "    # Write content to section\n",
        "    section.content = section_content.content\n",
        "\n",
        "    print('--- Writing Final Section: '+ section.name + ' Completed ---')\n",
        "\n",
        "    # Write the updated section to completed sections\n",
        "    return {\"completed_sections\": [section]}"
      ],
      "metadata": {
        "id": "rRSoWr_MAIun"
      },
      "id": "rRSoWr_MAIun",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Dynamic Parallelization Node Function - Parallelize Final Section Writing\n",
        "\n",
        "`Send(...)` is used to parallelize and call the `write_final_sections` once for each of the introduction and conclusion to write up the content (in parallel)"
      ],
      "metadata": {
        "id": "XIHk7dkbdGdn"
      },
      "id": "XIHk7dkbdGdn"
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.constants import Send\n",
        "\n",
        "def parallelize_final_section_writing(state: ReportState):\n",
        "    \"\"\" Write any final sections using the Send API to parallelize the process \"\"\"\n",
        "\n",
        "    # Kick off section writing in parallel via Send() API for any sections that do not require research\n",
        "    return [\n",
        "        Send(\"write_final_sections\",\n",
        "             {\"section\": s, \"report_sections_from_research\": state[\"report_sections_from_research\"]})\n",
        "                 for s in state[\"sections\"]\n",
        "                    if not s.research\n",
        "    ]"
      ],
      "metadata": {
        "id": "gaXMkCuZDP9h"
      },
      "id": "gaXMkCuZDP9h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile Final Report Node Function\n",
        "\n",
        "This function combines all the sections of the report together and compiles it into the final report document\n",
        "\n"
      ],
      "metadata": {
        "id": "fCwKY0o_dWeM"
      },
      "id": "fCwKY0o_dWeM"
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_final_report(state: ReportState):\n",
        "    \"\"\" Compile the final report \"\"\"\n",
        "\n",
        "    # Get sections\n",
        "    sections = state[\"sections\"]\n",
        "    completed_sections = {s.name: s.content for s in state[\"completed_sections\"]}\n",
        "\n",
        "    print('--- Compiling Final Report ---')\n",
        "\n",
        "    # Update sections with completed content while maintaining original order\n",
        "    for section in sections:\n",
        "        section.content = completed_sections[section.name]\n",
        "\n",
        "    # Compile final report\n",
        "    all_sections = \"\\n\\n\".join([s.content for s in sections])\n",
        "    # Escape unescaped $ symbols to display properly in Markdown\n",
        "    formatted_sections = all_sections.replace(\"\\\\$\", \"TEMP_PLACEHOLDER\")  # Temporarily mark already escaped $\n",
        "    formatted_sections = formatted_sections.replace(\"$\", \"\\\\$\")  # Escape all $\n",
        "    formatted_sections = formatted_sections.replace(\"TEMP_PLACEHOLDER\", \"\\\\$\")  # Restore originally escaped $\n",
        "\n",
        "# Now escaped_sections contains the properly escaped Markdown text\n",
        "\n",
        "\n",
        "    print('--- Compiling Final Report Done ---')\n",
        "\n",
        "    return {\"final_report\": formatted_sections}\n"
      ],
      "metadata": {
        "id": "PPlIQZl2Ddrk"
      },
      "id": "PPlIQZl2Ddrk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build our Report Writer Planning Agent\n",
        "\n",
        "We now bring all the defined components and sub-agent together and build our planning agent\n",
        "\n"
      ],
      "metadata": {
        "id": "i10VLrxKePMo"
      },
      "id": "i10VLrxKePMo"
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput)\n",
        "\n",
        "builder.add_node(\"generate_report_plan\", generate_report_plan)\n",
        "builder.add_node(\"section_builder_with_web_search\", section_builder_subagent)\n",
        "builder.add_node(\"format_completed_sections\", format_completed_sections)\n",
        "builder.add_node(\"write_final_sections\", write_final_sections)\n",
        "builder.add_node(\"compile_final_report\", compile_final_report)\n",
        "\n",
        "builder.add_edge(START, \"generate_report_plan\")\n",
        "builder.add_conditional_edges(\"generate_report_plan\",\n",
        "                              parallelize_section_writing,\n",
        "                              [\"section_builder_with_web_search\"])\n",
        "builder.add_edge(\"section_builder_with_web_search\", \"format_completed_sections\")\n",
        "builder.add_conditional_edges(\"format_completed_sections\",\n",
        "                              parallelize_final_section_writing,\n",
        "                              [\"write_final_sections\"])\n",
        "builder.add_edge(\"write_final_sections\", \"compile_final_report\")\n",
        "builder.add_edge(\"compile_final_report\", END)\n",
        "\n",
        "reporter_agent = builder.compile()"
      ],
      "metadata": {
        "id": "8WhUNRSJDLGX"
      },
      "id": "8WhUNRSJDLGX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(Image(reporter_agent.get_graph(xray=True).draw_mermaid_png()))"
      ],
      "metadata": {
        "id": "d0owAmm_j5I-"
      },
      "id": "d0owAmm_j5I-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run and Test our Agent"
      ],
      "metadata": {
        "id": "LfIg-JDVearE"
      },
      "id": "LfIg-JDVearE"
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from rich.console import Console\n",
        "from rich.markdown import Markdown as RichMarkdown\n",
        "\n",
        "async def call_planner_agent(agent, prompt, config={\"recursion_limit\": 50}, verbose=False):\n",
        "    events = agent.astream(\n",
        "        {'topic' : prompt},\n",
        "        config,\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "\n",
        "    async for event in events:\n",
        "        for k, v in event.items():\n",
        "            if verbose:\n",
        "                if k != \"__end__\":\n",
        "                    display(RichMarkdown(repr(k) + ' -> ' + repr(v)))\n",
        "            if k == 'final_report':\n",
        "                print('='*50)\n",
        "                print('Final Report:')\n",
        "                md = RichMarkdown(v)\n",
        "                display(md)"
      ],
      "metadata": {
        "id": "ddra7VuHbiwn"
      },
      "id": "ddra7VuHbiwn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Detailed report on how to build Agentic AI systems, design patterns and current frameworks\"\n",
        "await call_planner_agent(agent=reporter_agent,\n",
        "                         prompt=topic)"
      ],
      "metadata": {
        "id": "WlDHdzLpFPSO"
      },
      "id": "WlDHdzLpFPSO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Detailed report on how is NVIDIA winning the game against its competitors\"\n",
        "await call_planner_agent(agent=reporter_agent,\n",
        "                         prompt=topic)"
      ],
      "metadata": {
        "id": "SvT_7UGgGiQA"
      },
      "id": "SvT_7UGgGiQA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = \"Detailed report on how DeepSeek has disrupted the AI Market\"\n",
        "await call_planner_agent(agent=reporter_agent,\n",
        "                         prompt=topic)"
      ],
      "metadata": {
        "id": "W1ng0JUSKai8"
      },
      "id": "W1ng0JUSKai8",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "9hEI3WL328vZ",
        "lM0iTr7iC-17"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}